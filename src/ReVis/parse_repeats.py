from dataclasses import dataclass
# dataclass generates stuff like __init__() for classes automatically 
from enum import Enum
import time
import pandas as pd
from tqdm import tqdm
import subprocess as sp
import tempfile
import os
import parse_gff as gff




@dataclass
class Repeat:
    start:int
    end:int
    contig:str
    feature_id:str
    repeat_category:str

    @property
    def length(self):
        return int(self.end)-int(self.start) +1 # same reason as in Feature class
    
    @property
    def get_category(self):
        return [self.repeat_category, self.start, self.end]
    
    # get number of how many instances of each feature category are pesent in a gene
    @property
    def getFeatureStats(self):
        feature_stats = {}
        for feature in self.features:
            feature_stats[feature] = {len(self.features[feature])}
        return feature_stats
    
    def __str__(self):
        return(f"""repeat category: {self.repeat_category}") on contig: {self.contig} ;  from {str(self.start)} to {str(self.end)}""")
        


def parse_repeats_repeatmasker_outfile(filepath_out, verbose = True, filter_overlap = False, contig_list = []):
    """
    parse the .out file with all assigned repeats generated by repeatmasker.
    makes a dictionary with:
        { 
        contig1 : [list_of_repeats],
        contig2 : [list_of_repeats],
          ...
        } 
    with the list containing instances of the repeats class
    optionally a contig list can be provided so that only contigs that are included in the list are parsed and returned

    this function does not filter overlaps, because many levels of repeats can overlap through insertions into insertions into an original repeat.
    Overlaps can be filtered after parsing
    """

    base_outfile = False
    # check if the file is .out or .ori.out
    if filepath_out[-8:] == ".ori.out":
        base_outfile = True

    if verbose:
        print(f"File that is being parsed: {filepath_out}")
        if base_outfile:
            print(f"the outfile is the base file")
        else:
            print(f"weirdly formatted outfile, not .ori.out")
        start_time = time.perf_counter()
        if len(contig_list)>0:
            print(f"\t(a contig list has been included, only contigs that are represented in the list will be parsed)")


    gfffile={}

    #### parse dataframe from .out file
    ## clean the outfile first in a temporary file by removing the tailing " *" that some lines have 
    if base_outfile == False:
        temp_file = tempfile.NamedTemporaryFile(delete=False)
        command = ["sed", "s/ \*$//", filepath_out]

        if verbose:
            print(f"* Prepare input file:\n\tcleaning (may take a few seconds if there is a lot of repeats): \n\t\t{filepath_out}, creating the temporary file {temp_file.name}")

        with open(temp_file.name, 'w') as temp_output:
            sp.run(command, stdout=temp_output, check=True)

        if verbose:
            end_time = time.perf_counter()
            execution_time = end_time - start_time
            print(f"\tdone cleaning ({execution_time:.2f} seconds), reading file ...")
            start_time = time.perf_counter()

        out_headers = ["SW score", "perc div.", "perc del.", "perc ins.", "contig", "position in query begin", "position in query end", "position in query (left)", "something unidentified", "matching repeat", "repeat class/family", "position in repeat begin", "position in repeat end", "position in repeat (left)", "ID"]
        repeats_df = pd.read_csv(temp_file.name, sep="\s+", comment="#", skiprows=3, names=out_headers, dtype=str, index_col=False)
        # print(repeats_df)
        # print(repeats_df["repeat class/family"])

        os.remove(temp_file.name)
        ####
    
    else:
        out_headers = ["SW score", "perc div.", "perc del.", "perc ins.", "contig", "position in query begin", "position in query end", "position in query (left)", "something unidentified", "matching repeat", "repeat class/family", "position in repeat begin", "position in repeat end", "position in repeat (left)", "ID"]
        repeats_df = pd.read_csv(filepath_out, sep="\s+", comment="#", names=out_headers, dtype=str, index_col=False)


    if verbose:
        end_time = time.perf_counter()
        execution_time = end_time - start_time
        print(f"\tdone reading ({execution_time:.2f} seconds), filtering out contigs shorter than the window length (may take long for fragmented assemblies) ...")
        start_time = time.perf_counter()

    repeats_df = repeats_df[["contig", "position in query begin", "position in query end", "repeat class/family", "ID"]]

    repeats_before_filter = len(repeats_df)

    repeats_list:list[list[str]] = []
    if len(contig_list)>0:
        for contig in contig_list:
            repeats_contig = repeats_df[repeats_df["contig"] == contig]
            repeats_list.extend(repeats_contig.values.tolist())
            # if verbose:
            #     print(f"{contig} : {len(repeats_contig)} repeats, (in total: {len(repeats_list)})")
    else:
        repeats_list = repeats_df.values.tolist()

    if verbose and len(contig_list)>0:
        print(f"\t\t{repeats_before_filter} repeats before filtering\n\t\t{len(repeats_list)} repeats after filtering")

    if verbose:
        end_time = time.perf_counter()
        execution_time = end_time - start_time
        print(f"\tdone filtering ({execution_time:.2f} seconds)\n")
        start_time = time.perf_counter()
        print("* parse gff...")
    
    # check for overlaps and filter them out
    prev_end = 0
    count_overlap = 0
    bp_overlap = 0

    for line in tqdm(repeats_list):

        # parse gff file
        # more info on file format and columns here: https://www.ensembl.org/info/website/upload/gff.html?redirect=no
        contig,start_original,end_original,repeat_category,id=line
        
        # if repeat direction is inverse, flip it
        if int(end_original)<int(start_original):
            start = int(end_original)
            end = int(start_original)
        else:
            end = int(end_original)
            start = int(start_original)
        
        # if there's an overlap
        if int(start) < int(prev_end):
            count_overlap+=1
            if filter_overlap:
                bp_overlap = bp_overlap + int(prev_end)-int(start)
                start = int(prev_end)
        prev_end = end

        id = str(id)

        repeat_category = repeat_category.strip().split("/")[0]

        if len(contig_list)>0 and contig not in contig_list:
            continue

        if contig not in gfffile:
            gfffile[contig] = []

        if len(id)==0:
            raise RuntimeError(f"no id property found for repeat in line: {line}")
        
        newrepeat=Repeat(start,end,contig,feature_id=id, repeat_category=repeat_category)
        gfffile[contig].append(newrepeat)

    if verbose:
        end_time = time.perf_counter()
        execution_time = end_time - start_time
        print(f"\tparsing time: {execution_time:.2f} seconds")

        print(f"\ttotal number of contigs: {len(gfffile)}")

        print(f"\tnumber of repeats that overlap with a repeat ahead of them: {count_overlap}\n\t --> {bp_overlap} bp of overlapping repeats removed during parsing of the gff file")


    return(gfffile)